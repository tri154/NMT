{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "1bgfneFxJPED"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Dependencies and Data"
      ],
      "metadata": {
        "id": "8kR9LFCOJYFz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5cxj1pLDPuR7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "!pip install sacrebleu\n",
        "!git clone https://github.com/tri154/NMT.git\n",
        "%cd NMT\n",
        "!git checkout 2ad5a071a576"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#With LoRA"
      ],
      "metadata": {
        "id": "1bgfneFxJPED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vietnamese to english\n",
        "!python test_finetune.py --base_model \"unsloth/Qwen2.5-3B-Instruct\" \\\n",
        "                        --lora_model \"ledas/Qwen2.5-3B-Instruct-LoRA-SFT\" \\\n",
        "                        --test_src \"./data/vlsp_sft/public_test.vi\" \\\n",
        "                        --test_trg \"./data/vlsp_sft/public_test.en\" \\\n",
        "                        --direction \"vi2en\" \\\n",
        "                        --batch_size 16 \\\n",
        "                        # --debug 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRIu_GN3pW4U",
        "outputId": "26355eda-da51-4c68-ec21-8c52d8a776c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "2025-12-19 07:26:13.425830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766129173.665721    1529 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766129173.732235    1529 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766129174.230632    1529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766129174.230676    1529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766129174.230681    1529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766129174.230685    1529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-19 07:26:14.279565: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.12.7: Fast Qwen2 patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "model.safetensors: 100% 2.36G/2.36G [00:28<00:00, 83.2MB/s]\n",
            "generation_config.json: 100% 271/271 [00:00<00:00, 2.53MB/s]\n",
            "tokenizer_config.json: 7.36kB [00:00, 31.3MB/s]\n",
            "vocab.json: 2.78MB [00:00, 135MB/s]\n",
            "merges.txt: 1.67MB [00:00, 124MB/s]\n",
            "added_tokens.json: 100% 605/605 [00:00<00:00, 5.58MB/s]\n",
            "special_tokens_map.json: 100% 614/614 [00:00<00:00, 5.05MB/s]\n",
            "tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 13.3MB/s]\n",
            "adapter_config.json: 1.21kB [00:00, 7.62MB/s]\n",
            "adapter_model.safetensors: 100% 479M/479M [00:04<00:00, 103MB/s]\n",
            "Map: 100% 3000/3000 [00:00<00:00, 9254.52 examples/s]\n",
            "Inference with max_new_tokens = 127 .\n",
            "100% 188/188 [47:05<00:00, 15.03s/it]\n",
            "BLEU score: 24.693146275049536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# english to vietnamese\n",
        "!python test_finetune.py --base_model \"unsloth/Qwen2.5-3B-Instruct\" \\\n",
        "                        --lora_model \"ledas/Qwen2.5-3B-Instruct-LoRA-SFT\" \\\n",
        "                        --test_src \"./data/vlsp_sft/public_test.en\" \\\n",
        "                        --test_trg \"./data/vlsp_sft/public_test.vi\" \\\n",
        "                        --direction \"en2vi\" \\\n",
        "                        --batch_size 16 \\\n",
        "                        # --debug 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_iL4cQ-rp_W",
        "outputId": "61692470-a59b-4444-d3fe-f18a81998ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "2025-12-19 08:16:58.866841: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766132218.901107   14489 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766132218.912966   14489 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766132218.943575   14489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766132218.943608   14489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766132218.943615   14489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766132218.943622   14489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-19 08:16:58.952326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.12.7: Fast Qwen2 patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Map: 100% 3000/3000 [00:00<00:00, 10497.18 examples/s]\n",
            "Inference with max_new_tokens = 151 .\n",
            "100% 188/188 [57:36<00:00, 18.38s/it]\n",
            "BLEU score: 35.07600563997479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#W/O LoRA"
      ],
      "metadata": {
        "id": "-ClYKO4oJKb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vietnamese to english\n",
        "!python test_finetune.py --base_model \"unsloth/Qwen2.5-3B-Instruct\" \\\n",
        "                        --test_src \"./data/vlsp_sft/public_test.vi\" \\\n",
        "                        --test_trg \"./data/vlsp_sft/public_test.en\" \\\n",
        "                        --direction \"vi2en\" \\\n",
        "                        --batch_size 16 \\\n",
        "                        # --lora_model \"ledas/Qwen2.5-3B-Instruct-LoRA-SFT\" \\\n",
        "                        # --debug 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyxEbhHD5r1n",
        "outputId": "eff37915-1e99-4c13-8d55-a59ef2b0c0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "2025-12-19 09:18:45.506422: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766135925.529460   30054 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766135925.536886   30054 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766135925.556862   30054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766135925.556895   30054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766135925.556899   30054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766135925.556903   30054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-19 09:18:45.562127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.12.7: Fast Qwen2 patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Map: 100% 3000/3000 [00:00<00:00, 9576.56 examples/s]\n",
            "Inference with max_new_tokens = 127 .\n",
            "100% 188/188 [41:20<00:00, 13.20s/it]\n",
            "BLEU score: 14.952244177680397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# english to vietnamese\n",
        "!python test_finetune.py --base_model \"unsloth/Qwen2.5-3B-Instruct\" \\\n",
        "                        --test_src \"./data/vlsp_sft/public_test.en\" \\\n",
        "                        --test_trg \"./data/vlsp_sft/public_test.vi\" \\\n",
        "                        --direction \"en2vi\" \\\n",
        "                        --batch_size 16 \\\n",
        "                        # --lora_model \"ledas/Qwen2.5-3B-Instruct-LoRA-SFT\" \\\n",
        "                        # --debug 1"
      ],
      "metadata": {
        "id": "Ez_oClmF55O7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00c1a0d3-7bcf-4a63-ee83-32d54eb5aa54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "2025-12-19 10:33:34.094107: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766140414.357682    3080 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766140414.422962    3080 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766140414.916175    3080 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766140414.916230    3080 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766140414.916234    3080 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766140414.916241    3080 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-19 10:33:34.961929: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.12.7: Fast Qwen2 patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "model.safetensors: 100% 2.36G/2.36G [00:22<00:00, 103MB/s]\n",
            "generation_config.json: 100% 271/271 [00:00<00:00, 1.59MB/s]\n",
            "tokenizer_config.json: 7.36kB [00:00, 23.3MB/s]\n",
            "vocab.json: 2.78MB [00:00, 70.5MB/s]\n",
            "merges.txt: 1.67MB [00:00, 116MB/s]\n",
            "added_tokens.json: 100% 605/605 [00:00<00:00, 5.50MB/s]\n",
            "special_tokens_map.json: 100% 614/614 [00:00<00:00, 3.77MB/s]\n",
            "tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 12.3MB/s]\n",
            "Map: 100% 3000/3000 [00:00<00:00, 9614.67 examples/s]\n",
            "Inference with max_new_tokens = 151 .\n",
            "100% 188/188 [43:15<00:00, 13.81s/it]\n",
            "BLEU score: 21.324403169349644\n"
          ]
        }
      ]
    }
  ]
}