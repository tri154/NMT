device: cuda
# folders
log_path: logs/log.txt
result_path: results/
data_dir: data/

# preprocessing
num_examples: -1
train_max_len: 50
lowercase: false

# word tokenizer
min_freq: 5

# training
num_epochs: 1
train_batch_size: 32
num_warmups: 0.04
eval_freq: -1 # every $ batchs
print_freq: 200
# optimizer
lr: !!float 1.0 # scheduler determines lr
opt_b1: 0.9
opt_b2: 0.98
opt_eps: !!float 1e-9

# inference
test_batch_size: 4
#beam
beam_size: 3
beam_max_length: 10 # should be smaller than pe_max_seq_len
length_penalty: 0.6

# model
dropout: 0.1
d_model: 512
d_ff: 2048
n_heads: 8
pe_max_seq_len: 200

n_encoder_layers: 6
n_decoder_layers: 6
